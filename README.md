# Multi-Armed Bandit

## Final Project: Algorithmic Trading Strategies Under Uncertainty

In this project, we aim to explore and implement algorithmic trading strategies under conditions of uncertainty. Our objective is to apply concepts from this semester to algorithmic trading, using key algorithms that deal with unpredictable factors in the stock market. These strategies include Optimal Stopping for trade timing, Multi-Armed Bandit for portfolio allocation, Bayesian Updating for price prediction, and Reinforcement Learning for policy improvement. By implementing these algorithms, we seek to model and optimise decision-making under uncertain market conditions, contributing to algorithmic finance.

## Problem Statement

The stock market is inherently uncertain, with prices and trends influenced by countless unpredictable factors. While traditional trading strategies rely on historical data and deterministic approaches, these methods often fail under high volatility. With recent advancements in algorithmic and probabilistic methods, we seek to design algorithms that perform well despite this unpredictability. While some financial models incorporate basic uncertainty, thereâ€™s still a gap in strategies that can adapt and improve dynamically in uncertain environments.

## Project design

We will take a quantitative and experimental approach, implementing each of the algorithms on historical market data and synthetic test cases. This design allows us to analyse both real-world relevance and theoretical robustness.

## Multi-Armed Bandit Implementation

For the Multi-Armed Bandit implementation, we will simulate multiple assets, with bandit arms representing different stocks. We will track the allocation of capital based on exploration vs. exploitation.
